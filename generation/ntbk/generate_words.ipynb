{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "source": [
    "# Notebook to generate the words onset from the sentences\n",
    "\n",
    "First, download all the text grids, using the df that has all the sentences information (textual), and the audio files linked to each sentence.\n",
    "\n",
    "To get a textgrid, you need to input both the sentence text, and the audio file."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Setting up the necessary files for the API calls"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get all the sentences\n",
    "from pathlib import Path\n",
    "import mne\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "data_path = Path('/home/co/data/MindSentences/le_240431/241210')\n",
    "\n",
    "dataset_file = data_path / 'final_dataset.csv'\n",
    "\n",
    "df = pd.read_csv(dataset_file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>tense</th>\n",
       "      <th>dataset</th>\n",
       "      <th>theme</th>\n",
       "      <th>num_words</th>\n",
       "      <th>structure</th>\n",
       "      <th>audio_filename</th>\n",
       "      <th>sentence_id</th>\n",
       "      <th>numerosity</th>\n",
       "      <th>sentence</th>\n",
       "      <th>audio_path</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>future</td>\n",
       "      <td>naturalistic</td>\n",
       "      <td>emotion</td>\n",
       "      <td>7</td>\n",
       "      <td>simple</td>\n",
       "      <td>nat_00282.wav</td>\n",
       "      <td>nat_00282</td>\n",
       "      <td>plural</td>\n",
       "      <td>The kids will find joy in games</td>\n",
       "      <td>/home/co/data/MindSentences/le_240431/241210/a...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>future</td>\n",
       "      <td>naturalistic</td>\n",
       "      <td>relationship</td>\n",
       "      <td>11</td>\n",
       "      <td>preposition</td>\n",
       "      <td>nat_02008.wav</td>\n",
       "      <td>nat_02008</td>\n",
       "      <td>singular</td>\n",
       "      <td>Will your cousin not be at the museum with us ...</td>\n",
       "      <td>/home/co/data/MindSentences/le_240431/241210/a...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>present</td>\n",
       "      <td>naturalistic</td>\n",
       "      <td>food</td>\n",
       "      <td>5</td>\n",
       "      <td>simple</td>\n",
       "      <td>nat_01713.wav</td>\n",
       "      <td>nat_01713</td>\n",
       "      <td>singular</td>\n",
       "      <td>The bread isn't baked yet</td>\n",
       "      <td>/home/co/data/MindSentences/le_240431/241210/a...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>present</td>\n",
       "      <td>naturalistic</td>\n",
       "      <td>humanity</td>\n",
       "      <td>9</td>\n",
       "      <td>preposition</td>\n",
       "      <td>nat_01666.wav</td>\n",
       "      <td>nat_01666</td>\n",
       "      <td>singular</td>\n",
       "      <td>Study the painting with a guide from the gallery</td>\n",
       "      <td>/home/co/data/MindSentences/le_240431/241210/a...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>past</td>\n",
       "      <td>naturalistic</td>\n",
       "      <td>health</td>\n",
       "      <td>7</td>\n",
       "      <td>independent</td>\n",
       "      <td>nat_02066.wav</td>\n",
       "      <td>nat_02066</td>\n",
       "      <td>singular</td>\n",
       "      <td>I wasn't aware there was therapy available</td>\n",
       "      <td>/home/co/data/MindSentences/le_240431/241210/a...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3275</th>\n",
       "      <td>past</td>\n",
       "      <td>controlled</td>\n",
       "      <td>transport</td>\n",
       "      <td>10</td>\n",
       "      <td>standard_object_c</td>\n",
       "      <td>ctrl_01195.wav</td>\n",
       "      <td>ctrl_01195</td>\n",
       "      <td>singular</td>\n",
       "      <td>The enthusiastic child that everyone observed ...</td>\n",
       "      <td>/home/co/data/MindSentences/le_240431/241210/a...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3276</th>\n",
       "      <td>past</td>\n",
       "      <td>controlled</td>\n",
       "      <td>transport</td>\n",
       "      <td>13</td>\n",
       "      <td>nested</td>\n",
       "      <td>ctrl_01196.wav</td>\n",
       "      <td>ctrl_01196</td>\n",
       "      <td>singular</td>\n",
       "      <td>The child who told a story that entertained th...</td>\n",
       "      <td>/home/co/data/MindSentences/le_240431/241210/a...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3277</th>\n",
       "      <td>past</td>\n",
       "      <td>controlled</td>\n",
       "      <td>transport</td>\n",
       "      <td>14</td>\n",
       "      <td>nested_a</td>\n",
       "      <td>ctrl_01197.wav</td>\n",
       "      <td>ctrl_01197</td>\n",
       "      <td>singular</td>\n",
       "      <td>The child who narrated a story that entertaine...</td>\n",
       "      <td>/home/co/data/MindSentences/le_240431/241210/a...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3278</th>\n",
       "      <td>past</td>\n",
       "      <td>controlled</td>\n",
       "      <td>transport</td>\n",
       "      <td>14</td>\n",
       "      <td>nested_b</td>\n",
       "      <td>ctrl_01198.wav</td>\n",
       "      <td>ctrl_01198</td>\n",
       "      <td>singular</td>\n",
       "      <td>The eager child who told a story that amused t...</td>\n",
       "      <td>/home/co/data/MindSentences/le_240431/241210/a...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3279</th>\n",
       "      <td>past</td>\n",
       "      <td>controlled</td>\n",
       "      <td>transport</td>\n",
       "      <td>15</td>\n",
       "      <td>nested_c</td>\n",
       "      <td>ctrl_01199.wav</td>\n",
       "      <td>ctrl_01199</td>\n",
       "      <td>singular</td>\n",
       "      <td>The eager child who told a story that amused t...</td>\n",
       "      <td>/home/co/data/MindSentences/le_240431/241210/a...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>3280 rows × 10 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "        tense       dataset         theme  num_words          structure  \\\n",
       "0      future  naturalistic       emotion          7             simple   \n",
       "1      future  naturalistic  relationship         11        preposition   \n",
       "2     present  naturalistic          food          5             simple   \n",
       "3     present  naturalistic      humanity          9        preposition   \n",
       "4        past  naturalistic        health          7        independent   \n",
       "...       ...           ...           ...        ...                ...   \n",
       "3275     past    controlled     transport         10  standard_object_c   \n",
       "3276     past    controlled     transport         13             nested   \n",
       "3277     past    controlled     transport         14           nested_a   \n",
       "3278     past    controlled     transport         14           nested_b   \n",
       "3279     past    controlled     transport         15           nested_c   \n",
       "\n",
       "      audio_filename sentence_id numerosity  \\\n",
       "0      nat_00282.wav   nat_00282     plural   \n",
       "1      nat_02008.wav   nat_02008   singular   \n",
       "2      nat_01713.wav   nat_01713   singular   \n",
       "3      nat_01666.wav   nat_01666   singular   \n",
       "4      nat_02066.wav   nat_02066   singular   \n",
       "...              ...         ...        ...   \n",
       "3275  ctrl_01195.wav  ctrl_01195   singular   \n",
       "3276  ctrl_01196.wav  ctrl_01196   singular   \n",
       "3277  ctrl_01197.wav  ctrl_01197   singular   \n",
       "3278  ctrl_01198.wav  ctrl_01198   singular   \n",
       "3279  ctrl_01199.wav  ctrl_01199   singular   \n",
       "\n",
       "                                               sentence  \\\n",
       "0                       The kids will find joy in games   \n",
       "1     Will your cousin not be at the museum with us ...   \n",
       "2                             The bread isn't baked yet   \n",
       "3      Study the painting with a guide from the gallery   \n",
       "4            I wasn't aware there was therapy available   \n",
       "...                                                 ...   \n",
       "3275  The enthusiastic child that everyone observed ...   \n",
       "3276  The child who told a story that entertained th...   \n",
       "3277  The child who narrated a story that entertaine...   \n",
       "3278  The eager child who told a story that amused t...   \n",
       "3279  The eager child who told a story that amused t...   \n",
       "\n",
       "                                             audio_path  \n",
       "0     /home/co/data/MindSentences/le_240431/241210/a...  \n",
       "1     /home/co/data/MindSentences/le_240431/241210/a...  \n",
       "2     /home/co/data/MindSentences/le_240431/241210/a...  \n",
       "3     /home/co/data/MindSentences/le_240431/241210/a...  \n",
       "4     /home/co/data/MindSentences/le_240431/241210/a...  \n",
       "...                                                 ...  \n",
       "3275  /home/co/data/MindSentences/le_240431/241210/a...  \n",
       "3276  /home/co/data/MindSentences/le_240431/241210/a...  \n",
       "3277  /home/co/data/MindSentences/le_240431/241210/a...  \n",
       "3278  /home/co/data/MindSentences/le_240431/241210/a...  \n",
       "3279  /home/co/data/MindSentences/le_240431/241210/a...  \n",
       "\n",
       "[3280 rows x 10 columns]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# First: rename all the .wav files in the audio folder into another folder called audio_mp3\n",
    "\n",
    "audio_path = data_path / 'audio'\n",
    "audio_mp3_path = data_path / 'audio_mp3'\n",
    "audio_mp3_path.mkdir(exist_ok=True)\n",
    "\n",
    "for audio_file in audio_path.glob('*.wav'):\n",
    "    audio_file.rename(audio_mp3_path / audio_file.name.replace('.wav', '.mp3'))\n",
    "\n",
    "# Second: create a new column in the dataframe with the path to the audio file\n",
    "\n",
    "df['audio_path'] = df['audio_filename'].apply(lambda x: str(audio_mp3_path / x.replace('.wav', '.mp3')))\n",
    "df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Code to download all the textgrids\n",
    "\n",
    "Code to run beforehand in order to get all the textgrids using the WebMausAPI directly, instead of doing it by hand "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>sentence_id</th>\n",
       "      <th>intervals</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>nat_00282</td>\n",
       "      <td>[{'start': 0.0, 'end': 0.05, 'text': ''}, {'st...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>nat_02008</td>\n",
       "      <td>[{'start': 0.0, 'end': 0.07, 'text': ''}, {'st...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>nat_01713</td>\n",
       "      <td>[{'start': 0.0, 'end': 0.03, 'text': ''}, {'st...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>nat_01666</td>\n",
       "      <td>[{'start': 0.0, 'end': 0.14, 'text': ''}, {'st...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>nat_02066</td>\n",
       "      <td>[{'start': 0.0, 'end': 0.06, 'text': ''}, {'st...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3275</th>\n",
       "      <td>ctrl_01195</td>\n",
       "      <td>[{'start': 0.0, 'end': 0.05, 'text': ''}, {'st...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3276</th>\n",
       "      <td>ctrl_01196</td>\n",
       "      <td>[{'start': 0.0, 'end': 0.03, 'text': ''}, {'st...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3277</th>\n",
       "      <td>ctrl_01197</td>\n",
       "      <td>[{'start': 0.0, 'end': 0.05, 'text': ''}, {'st...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3278</th>\n",
       "      <td>ctrl_01198</td>\n",
       "      <td>[{'start': 0.0, 'end': 0.05, 'text': ''}, {'st...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3279</th>\n",
       "      <td>ctrl_01199</td>\n",
       "      <td>[{'start': 0.0, 'end': 0.05, 'text': ''}, {'st...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>3280 rows × 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     sentence_id                                          intervals\n",
       "0      nat_00282  [{'start': 0.0, 'end': 0.05, 'text': ''}, {'st...\n",
       "1      nat_02008  [{'start': 0.0, 'end': 0.07, 'text': ''}, {'st...\n",
       "2      nat_01713  [{'start': 0.0, 'end': 0.03, 'text': ''}, {'st...\n",
       "3      nat_01666  [{'start': 0.0, 'end': 0.14, 'text': ''}, {'st...\n",
       "4      nat_02066  [{'start': 0.0, 'end': 0.06, 'text': ''}, {'st...\n",
       "...          ...                                                ...\n",
       "3275  ctrl_01195  [{'start': 0.0, 'end': 0.05, 'text': ''}, {'st...\n",
       "3276  ctrl_01196  [{'start': 0.0, 'end': 0.03, 'text': ''}, {'st...\n",
       "3277  ctrl_01197  [{'start': 0.0, 'end': 0.05, 'text': ''}, {'st...\n",
       "3278  ctrl_01198  [{'start': 0.0, 'end': 0.05, 'text': ''}, {'st...\n",
       "3279  ctrl_01199  [{'start': 0.0, 'end': 0.05, 'text': ''}, {'st...\n",
       "\n",
       "[3280 rows x 2 columns]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import requests\n",
    "from pathlib import Path\n",
    "from pydub import AudioSegment\n",
    "import tempfile\n",
    "import os\n",
    "import re\n",
    "\n",
    "# For each sentence, send it to MAUS and get the alignment for each word. \n",
    "# The final goal is to have a dataframe with for each sentence: its word starts and durations\n",
    "\n",
    "import xml.etree.ElementTree as ET\n",
    "\n",
    "def download_textgrid(download_link):\n",
    "    try:\n",
    "        response = requests.get(download_link)\n",
    "        response.raise_for_status()\n",
    "        return response.text\n",
    "    except Exception as e:\n",
    "        print(f\"Error downloading TextGrid: {str(e)}\")\n",
    "        raise\n",
    "\n",
    "def parse_textgrid(textgrid_content):\n",
    "    intervals = []\n",
    "    interval_pattern = r'intervals \\[\\d+\\]:\\n\\s*xmin = ([0-9.]+)\\n\\s*xmax = ([0-9.]+)\\n\\s*text = \"(.*?)\"'\n",
    "    matches = re.findall(interval_pattern, textgrid_content, re.DOTALL)\n",
    "    for match in matches:\n",
    "        start, end, text = match\n",
    "        intervals.append({'start': float(start), 'end': float(end), 'text': text})\n",
    "    return intervals\n",
    "\n",
    "def test_webmaus_call(original_path, text):\n",
    "    url = \"https://clarin.phonetik.uni-muenchen.de/BASWebServices/services/runMAUSBasic\"\n",
    "    temp_txt = Path('temp.txt')\n",
    "    temp_wav_path = None\n",
    "    files = {}\n",
    "    \n",
    "    try:\n",
    "\n",
    "        cleaned_text = text.replace(\"'\", \"'\")\n",
    "        temp_txt.write_text(cleaned_text)\n",
    "        \n",
    "        files = {\n",
    "            'SIGNAL': open(original_path, 'rb'),\n",
    "            'TEXT': open(temp_txt, 'rb')\n",
    "        }\n",
    "        \n",
    "        params = {\n",
    "            'LANGUAGE': 'eng-US',\n",
    "            'OUTFORMAT': 'TextGrid'\n",
    "        }\n",
    "        \n",
    "        response = requests.post(url, files=files, data=params, timeout=30)\n",
    "        \n",
    "        if response.content.startswith(b'<'):\n",
    "            root = ET.fromstring(response.content)\n",
    "            success = root.find('success').text\n",
    "            if success == 'false':\n",
    "                error_msg = response.content.decode()\n",
    "                raise Exception(f\"WebMAUS processing failed: {error_msg}\")\n",
    "            \n",
    "            download_link = root.find('downloadLink').text\n",
    "            if download_link:\n",
    "                return download_link\n",
    "        \n",
    "        return response.content.decode()\n",
    "            \n",
    "    except Exception as e:\n",
    "        raise\n",
    "    \n",
    "    finally:\n",
    "        if temp_txt.exists():\n",
    "            temp_txt.unlink()\n",
    "        \n",
    "        if temp_wav_path and os.path.exists(temp_wav_path):\n",
    "            os.remove(temp_wav_path)\n",
    "        \n",
    "        for f in files.values():\n",
    "            try:\n",
    "                f.close()\n",
    "            except:\n",
    "                pass\n",
    "\n",
    "# Process each sentence in the dataframe\n",
    "results = []\n",
    "\n",
    "# Test:\n",
    "df_test = df.head(2)\n",
    "for index, row in df.iterrows():\n",
    "# for index, row in df_test.iterrows():\n",
    "    audio_path = Path(row['audio_path'])\n",
    "    text = row['sentence']\n",
    "    \n",
    "    try:\n",
    "        result_link = test_webmaus_call(audio_path, text)\n",
    "        if result_link:\n",
    "            textgrid_content = download_textgrid(result_link)\n",
    "            intervals = parse_textgrid(textgrid_content)\n",
    "            results.append({\n",
    "                'sentence_id': row['sentence_id'],\n",
    "                'intervals': intervals\n",
    "            })\n",
    "            # Save the textgrid content to a txt file\n",
    "            with open(f\"textgrid_{row['sentence_id']}.txt\", \"w\") as f:\n",
    "                f.write(textgrid_content)\n",
    "    except Exception as e:\n",
    "        print(f\"Error processing sentence {row['sentence_id']}: {str(e)}\")\n",
    "        # Save the error message to a txt file\n",
    "        with open(f\"error_{row['sentence_id']}.txt\", \"w\") as f:\n",
    "            f.write(str(e))\n",
    "\n",
    "# Create a new dataframe with the results\n",
    "df_intervals = pd.DataFrame(results)\n",
    "df_intervals"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Clean the textgrids"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing complete!\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import shutil\n",
    "\n",
    "# Create necessary directories\n",
    "os.makedirs(\"original_textgrids\", exist_ok=True)\n",
    "os.makedirs(\"cleaned_textgrids\", exist_ok=True)\n",
    "\n",
    "# Move all existing TextGrid files to original_textgrids folder\n",
    "for filename in os.listdir():\n",
    "    if filename.endswith('.txt'):\n",
    "        shutil.move(filename, os.path.join(\"original_textgrids\", filename))\n",
    "\n",
    "# Process each file in the original_textgrids folder\n",
    "for filename in os.listdir(\"original_textgrids\"):\n",
    "    if filename.endswith('.txt'):\n",
    "        with open(os.path.join(\"original_textgrids\", filename), 'r', encoding='utf-8') as file:\n",
    "            content = file.read()\n",
    "            \n",
    "        # Split the content into items\n",
    "        items = content.split('item [')[1:]\n",
    "        \n",
    "        # Find the ORT-MAU item (should be the first one)\n",
    "        ort_mau = None\n",
    "        for item in items:\n",
    "            if '\"ORT-MAU\"' in item:\n",
    "                ort_mau = item\n",
    "                break\n",
    "                \n",
    "        if ort_mau:\n",
    "            # Extract all intervals\n",
    "            intervals = []\n",
    "            lines = ort_mau.split('\\n')\n",
    "            \n",
    "            # Get header information\n",
    "            header_lines = []\n",
    "            for line in content.split('\\n'):\n",
    "                if 'item [' in line:\n",
    "                    break\n",
    "                header_lines.append(line)\n",
    "                \n",
    "            # Process intervals\n",
    "            collecting_interval = False\n",
    "            current_interval = []\n",
    "            cleaned_intervals = []\n",
    "            \n",
    "            for line in lines:\n",
    "                if 'intervals [' in line and not line.endswith('size'):\n",
    "                    collecting_interval = True\n",
    "                    current_interval = [line]\n",
    "                elif collecting_interval:\n",
    "                    current_interval.append(line)\n",
    "                    if 'text =' in line:\n",
    "                        text = line.split('=')[1].strip().strip('\"')\n",
    "                        if text and text != '\"\"' and not text.startswith('<'):\n",
    "                            cleaned_intervals.extend(current_interval)\n",
    "                        collecting_interval = False\n",
    "                        \n",
    "            # Create new content\n",
    "            new_content = '\\n'.join(header_lines) + '\\n'\n",
    "            new_content += 'item []:\\n    item [1]:\\n'\n",
    "            new_content += '        class = \"IntervalTier\"\\n'\n",
    "            new_content += '        name = \"ORT-MAU\"\\n'\n",
    "            new_content += f'        xmin = {content.split(\"xmin =\")[1].split()[0]}\\n'\n",
    "            new_content += f'        xmax = {content.split(\"xmax =\")[1].split()[0]}\\n'\n",
    "            new_content += f'        intervals: size = {len(cleaned_intervals) // 4}\\n'\n",
    "            new_content += '\\n'.join('        ' + line for line in cleaned_intervals)\n",
    "            \n",
    "            # Write the cleaned content to a new file\n",
    "            with open(os.path.join(\"cleaned_textgrids\", filename), 'w', encoding='utf-8') as file:\n",
    "                file.write(new_content)\n",
    "\n",
    "print(\"Processing complete!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def parse_textgrid(content):\n",
    "    lines = content.split('\\n')\n",
    "    words = []\n",
    "    in_item_1 = False\n",
    "    current_interval = None\n",
    "    \n",
    "    for i, line in enumerate(lines):\n",
    "        line = line.strip()\n",
    "        \n",
    "        # Start capturing when we hit item [1]\n",
    "        if 'item [1]:' in line:\n",
    "            in_item_1 = True\n",
    "            continue\n",
    "        \n",
    "        # Stop capturing when we hit item [2]\n",
    "        if 'item [2]:' in line:\n",
    "            in_item_1 = False\n",
    "            break\n",
    "            \n",
    "        if in_item_1:\n",
    "            if 'intervals [' in line:\n",
    "                current_interval = {}\n",
    "            elif 'xmin =' in line:\n",
    "                current_interval['start'] = float(line.split('=')[1].strip())\n",
    "            elif 'xmax =' in line:\n",
    "                current_interval['end'] = float(line.split('=')[1].strip())\n",
    "            elif 'text =' in line:\n",
    "                text = line.split('=')[1].strip().strip('\"')\n",
    "                current_interval['text'] = text\n",
    "                words.append(current_interval)\n",
    "                current_interval = None\n",
    "    \n",
    "    import pandas as pd\n",
    "    df = pd.DataFrame([(word['start'], word['end'], word['text']) \n",
    "                      for word in words],\n",
    "                     columns=['start', 'end', 'text'])\n",
    "    return df\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Transforming the new df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "       type                                           sentence  \\\n",
      "0  Sentence                    The kids will find joy in games   \n",
      "1      Word                    The kids will find joy in games   \n",
      "2      Word                    The kids will find joy in games   \n",
      "3      Word                    The kids will find joy in games   \n",
      "4      Word                    The kids will find joy in games   \n",
      "5      Word                    The kids will find joy in games   \n",
      "6      Word                    The kids will find joy in games   \n",
      "7      Word                    The kids will find joy in games   \n",
      "8  Sentence  Will your cousin not be at the museum with us ...   \n",
      "9      Word  Will your cousin not be at the museum with us ...   \n",
      "\n",
      "                                                text  start    end  \\\n",
      "0                    The kids will find joy in games  0.000  1.910   \n",
      "1                                                The  0.050  0.110   \n",
      "2                                               kids  0.110  0.455   \n",
      "3                                               will  0.455  0.560   \n",
      "4                                               find  0.560  0.810   \n",
      "5                                                joy  0.810  1.140   \n",
      "6                                                 in  1.140  1.260   \n",
      "7                                              games  1.260  1.910   \n",
      "8  Will your cousin not be at the museum with us ...  0.000  2.660   \n",
      "9                                               Will  0.070  0.200   \n",
      "\n",
      "   sequence_id                                         audio_path sentence_id  \n",
      "0            0  /home/co/data/MindSentences/le_240431/241210/a...   nat_00282  \n",
      "1            0  /home/co/data/MindSentences/le_240431/241210/a...   nat_00282  \n",
      "2            0  /home/co/data/MindSentences/le_240431/241210/a...   nat_00282  \n",
      "3            0  /home/co/data/MindSentences/le_240431/241210/a...   nat_00282  \n",
      "4            0  /home/co/data/MindSentences/le_240431/241210/a...   nat_00282  \n",
      "5            0  /home/co/data/MindSentences/le_240431/241210/a...   nat_00282  \n",
      "6            0  /home/co/data/MindSentences/le_240431/241210/a...   nat_00282  \n",
      "7            0  /home/co/data/MindSentences/le_240431/241210/a...   nat_00282  \n",
      "8            1  /home/co/data/MindSentences/le_240431/241210/a...   nat_02008  \n",
      "9            1  /home/co/data/MindSentences/le_240431/241210/a...   nat_02008  \n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import glob\n",
    "from pathlib import Path\n",
    "import re\n",
    "import os\n",
    "\n",
    "def parse_textgrid_for_words(textgrid_content):\n",
    "    # Extract word-level information from the cleaned TextGrids\n",
    "    word_pattern = r'intervals \\[\\d+\\]:\\s*xmin = ([0-9.]+)\\s*xmax = ([0-9.]+)\\s*text = \"(.*?)\"'\n",
    "    words = []\n",
    "    \n",
    "    matches = re.finditer(word_pattern, textgrid_content, re.DOTALL)\n",
    "    for match in matches:\n",
    "        start, end, text = match.groups()\n",
    "        if text.strip():  # Only include non-empty intervals\n",
    "            words.append({\n",
    "                'start': float(start),\n",
    "                'end': float(end),\n",
    "                'text': text.strip()\n",
    "            })\n",
    "    return words\n",
    "\n",
    "def create_combined_dataframe(original_df, textgrid_directory):\n",
    "    rows = []\n",
    "    \n",
    "    # First, add all sentences\n",
    "    for idx, row in original_df.iterrows():\n",
    "        # Add sentence-level entry\n",
    "        rows.append({\n",
    "            'type': 'Sentence',\n",
    "            'sentence': row['sentence'],\n",
    "            'text': row['sentence'],\n",
    "            'start': 0,\n",
    "            'end': None,  # Will be filled with the end time of the last word\n",
    "            'sequence_id': idx,\n",
    "            'audio_path': row['audio_path'],\n",
    "            'sentence_id': row['sentence_id']\n",
    "        })\n",
    "        \n",
    "        # Read and parse corresponding TextGrid file from the cleaned directory\n",
    "        textgrid_file = f\"textgrid_{row['sentence_id']}.txt\"\n",
    "        textgrid_path = Path(textgrid_directory) / 'cleaned_textgrids' / textgrid_file\n",
    "        \n",
    "        if textgrid_path.exists():\n",
    "            with open(textgrid_path, 'r', encoding='utf-8') as f:\n",
    "                textgrid_content = f.read()\n",
    "                \n",
    "            # Parse words and their timings\n",
    "            words = parse_textgrid_for_words(textgrid_content)\n",
    "            \n",
    "            # Add word-level entries\n",
    "            for word in words:\n",
    "                rows.append({\n",
    "                    'type': 'Word',\n",
    "                    'sentence': row['sentence'],\n",
    "                    'text': word['text'],\n",
    "                    'start': word['start'],\n",
    "                    'end': word['end'],\n",
    "                    'sequence_id': idx,\n",
    "                    'audio_path': row['audio_path'],\n",
    "                    'sentence_id': row['sentence_id']\n",
    "                })\n",
    "            \n",
    "            # Update the sentence end time with the last word's end time\n",
    "            if words:\n",
    "                rows[len(rows) - len(words) - 1]['end'] = words[-1]['end']\n",
    "    \n",
    "    # Create DataFrame from all rows\n",
    "    result_df = pd.DataFrame(rows)\n",
    "    \n",
    "    # Sort the DataFrame by sequence_id and start time\n",
    "    result_df = result_df.sort_values(['sequence_id', 'start'])\n",
    "    \n",
    "    return result_df\n",
    "\n",
    "# Specify the directory containing the TextGrid files\n",
    "textgrid_directory = \".\"  # Replace with actual directory path if different\n",
    "\n",
    "# Create the new DataFrame\n",
    "new_df = create_combined_dataframe(df, textgrid_directory)\n",
    "\n",
    "# Save the DataFrame to a CSV file\n",
    "new_df.to_csv('combined_data.csv', index=False)\n",
    "\n",
    "# Display the first few rows\n",
    "print(new_df.head(10))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(3280,)"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "new_df.sequence_id.unique().shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>type</th>\n",
       "      <th>sentence</th>\n",
       "      <th>text</th>\n",
       "      <th>start</th>\n",
       "      <th>end</th>\n",
       "      <th>sequence_id</th>\n",
       "      <th>audio_path</th>\n",
       "      <th>sentence_id</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Sentence</td>\n",
       "      <td>The kids will find joy in games</td>\n",
       "      <td>The kids will find joy in games</td>\n",
       "      <td>0.000</td>\n",
       "      <td>1.910</td>\n",
       "      <td>0</td>\n",
       "      <td>/home/co/data/MindSentences/le_240431/241210/a...</td>\n",
       "      <td>nat_00282</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Word</td>\n",
       "      <td>The kids will find joy in games</td>\n",
       "      <td>The</td>\n",
       "      <td>0.050</td>\n",
       "      <td>0.110</td>\n",
       "      <td>0</td>\n",
       "      <td>/home/co/data/MindSentences/le_240431/241210/a...</td>\n",
       "      <td>nat_00282</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Word</td>\n",
       "      <td>The kids will find joy in games</td>\n",
       "      <td>kids</td>\n",
       "      <td>0.110</td>\n",
       "      <td>0.455</td>\n",
       "      <td>0</td>\n",
       "      <td>/home/co/data/MindSentences/le_240431/241210/a...</td>\n",
       "      <td>nat_00282</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Word</td>\n",
       "      <td>The kids will find joy in games</td>\n",
       "      <td>will</td>\n",
       "      <td>0.455</td>\n",
       "      <td>0.560</td>\n",
       "      <td>0</td>\n",
       "      <td>/home/co/data/MindSentences/le_240431/241210/a...</td>\n",
       "      <td>nat_00282</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Word</td>\n",
       "      <td>The kids will find joy in games</td>\n",
       "      <td>find</td>\n",
       "      <td>0.560</td>\n",
       "      <td>0.810</td>\n",
       "      <td>0</td>\n",
       "      <td>/home/co/data/MindSentences/le_240431/241210/a...</td>\n",
       "      <td>nat_00282</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>31041</th>\n",
       "      <td>Word</td>\n",
       "      <td>The eager child who told a story that amused t...</td>\n",
       "      <td>passengers</td>\n",
       "      <td>2.780</td>\n",
       "      <td>3.510</td>\n",
       "      <td>3279</td>\n",
       "      <td>/home/co/data/MindSentences/le_240431/241210/a...</td>\n",
       "      <td>ctrl_01199</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>31042</th>\n",
       "      <td>Word</td>\n",
       "      <td>The eager child who told a story that amused t...</td>\n",
       "      <td>quickly</td>\n",
       "      <td>3.720</td>\n",
       "      <td>4.100</td>\n",
       "      <td>3279</td>\n",
       "      <td>/home/co/data/MindSentences/le_240431/241210/a...</td>\n",
       "      <td>ctrl_01199</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>31043</th>\n",
       "      <td>Word</td>\n",
       "      <td>The eager child who told a story that amused t...</td>\n",
       "      <td>boarded</td>\n",
       "      <td>4.100</td>\n",
       "      <td>4.490</td>\n",
       "      <td>3279</td>\n",
       "      <td>/home/co/data/MindSentences/le_240431/241210/a...</td>\n",
       "      <td>ctrl_01199</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>31044</th>\n",
       "      <td>Word</td>\n",
       "      <td>The eager child who told a story that amused t...</td>\n",
       "      <td>the</td>\n",
       "      <td>4.490</td>\n",
       "      <td>4.550</td>\n",
       "      <td>3279</td>\n",
       "      <td>/home/co/data/MindSentences/le_240431/241210/a...</td>\n",
       "      <td>ctrl_01199</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>31045</th>\n",
       "      <td>Word</td>\n",
       "      <td>The eager child who told a story that amused t...</td>\n",
       "      <td>train</td>\n",
       "      <td>4.550</td>\n",
       "      <td>4.970</td>\n",
       "      <td>3279</td>\n",
       "      <td>/home/co/data/MindSentences/le_240431/241210/a...</td>\n",
       "      <td>ctrl_01199</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>31046 rows × 8 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "           type                                           sentence  \\\n",
       "0      Sentence                    The kids will find joy in games   \n",
       "1          Word                    The kids will find joy in games   \n",
       "2          Word                    The kids will find joy in games   \n",
       "3          Word                    The kids will find joy in games   \n",
       "4          Word                    The kids will find joy in games   \n",
       "...         ...                                                ...   \n",
       "31041      Word  The eager child who told a story that amused t...   \n",
       "31042      Word  The eager child who told a story that amused t...   \n",
       "31043      Word  The eager child who told a story that amused t...   \n",
       "31044      Word  The eager child who told a story that amused t...   \n",
       "31045      Word  The eager child who told a story that amused t...   \n",
       "\n",
       "                                  text  start    end  sequence_id  \\\n",
       "0      The kids will find joy in games  0.000  1.910            0   \n",
       "1                                  The  0.050  0.110            0   \n",
       "2                                 kids  0.110  0.455            0   \n",
       "3                                 will  0.455  0.560            0   \n",
       "4                                 find  0.560  0.810            0   \n",
       "...                                ...    ...    ...          ...   \n",
       "31041                       passengers  2.780  3.510         3279   \n",
       "31042                          quickly  3.720  4.100         3279   \n",
       "31043                          boarded  4.100  4.490         3279   \n",
       "31044                              the  4.490  4.550         3279   \n",
       "31045                            train  4.550  4.970         3279   \n",
       "\n",
       "                                              audio_path sentence_id  \n",
       "0      /home/co/data/MindSentences/le_240431/241210/a...   nat_00282  \n",
       "1      /home/co/data/MindSentences/le_240431/241210/a...   nat_00282  \n",
       "2      /home/co/data/MindSentences/le_240431/241210/a...   nat_00282  \n",
       "3      /home/co/data/MindSentences/le_240431/241210/a...   nat_00282  \n",
       "4      /home/co/data/MindSentences/le_240431/241210/a...   nat_00282  \n",
       "...                                                  ...         ...  \n",
       "31041  /home/co/data/MindSentences/le_240431/241210/a...  ctrl_01199  \n",
       "31042  /home/co/data/MindSentences/le_240431/241210/a...  ctrl_01199  \n",
       "31043  /home/co/data/MindSentences/le_240431/241210/a...  ctrl_01199  \n",
       "31044  /home/co/data/MindSentences/le_240431/241210/a...  ctrl_01199  \n",
       "31045  /home/co/data/MindSentences/le_240431/241210/a...  ctrl_01199  \n",
       "\n",
       "[31046 rows x 8 columns]"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "new_df"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "nrst",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
